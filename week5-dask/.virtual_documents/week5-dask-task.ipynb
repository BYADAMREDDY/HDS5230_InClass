import dask.dataframe as ddf
import pandas as pd
from datetime import datetime
import numpy as np


PATH = "timeseries.csv"





data_types = {"name" : "str",
                "level" : "str",
                "city" : "str",
                "county" : "str",
                "state" : "str",
                "country" : "str",
                "population" : "float",
                "lat" : "float",
                "long" : "float",
                "url" : "str",
                "aggregate" : "str",
                "tz" : "str",
                "cases" : "float",
                "deaths" : "float",
                "recovered" : "str",
                "active" : "str",
                "tested" : "str",
                "hospitalized" : "str",
                "hospitalized_current" : "str",
                "discharged" : "str",
                "icu" : "str",
                "icu_current" : "str",
                "growthFactor" : "str",
                "date" : "str"}





df = ddf.read_csv(PATH, dtype = data_types)





df.groupby(by = ["country"]).count().compute().reset_index()["country"].tolist()





df["date"] = ddf.to_datetime(df["date"], format="%Y-%m-%d")


# from above we canunderstand that from the dataset we have two sections that contains united states lets initally filter them

df_us = df[df["country"] == "United States"] #, "United States Virgin Islands"])]


df_us.head()


df.shape[0].compute()


start_date = datetime.strptime("2020-01-01", r"%Y-%m-%d")
end_date = datetime.strptime("2021-02-28", r"%Y-%m-%d")

# now lets perfrom the filtering using the dates defined above
df_us_dt = df_us[(df_us["date"]>=start_date) & (df_us["date"]<=end_date)]



# see the shape as this can be useful for me to check whether we did really filter the data
df_us_dt.shape[0].compute()


df_us_dt.head()


# Compute total deaths for each state during the period
total_deaths = df_us_dt.groupby('state')['deaths'].sum().compute()

# Compute the average population for each state during the period
# You might want to average the population over the period for each state
avg_population = df_us_dt.groupby('state')['population'].mean().compute()

# Now, calculate the per-capita mortality as deaths / population
per_capita_mortality = total_deaths / avg_population

# Rank states based on per-capita mortality
ranked_states = per_capita_mortality.sort_values(ascending=False)

# Show the ranked states
print(ranked_states)


def year_month_udf(col):
    return f"{col.year}_{col.month}"


# Q3.3 for this extract the string year-month
df_us_dt["year_month"] = df_us_dt["date"].apply(year_month_udf)

total_cases = df_us_dt.groupby(by = ["state", "year_month"])["cases"].sum().compute()

total_deaths = df_us_dt.groupby(by = ["state", "year_month"])["deaths"].sum().compute()

CFR = (total_deaths / total_cases) * 100

CFR = CFR.reset_index()

pivot_table = CFR.pivot(index='state', columns='year_month')


df_us_dt["year_month"].unique().compute().tolist()


# pivot_table.reset_index(inplace = True)
pivot_table.columns = ['2020_1', '2020_2', '2020_3', '2020_4', '2020_5', '2020_6', '2020_7']





# fill the missing records
pivot_table["2020_8"] = np.nan
pivot_table["2020_9"] = np.nan
pivot_table["2020_10"] = np.nan
pivot_table["2020_11"] = np.nan
pivot_table["2020_12"] = np.nan
pivot_table["2021_1"] = np.nan
pivot_table["2021_2"] = np.nan

pivot_table = pivot_table[['2020_1', '2020_2', '2020_3', '2020_4', '2020_5', '2020_6', '2020_7',
                           '2020_8', '2020_9', '2020_10', '2020_11', '2020_12', '2021_1', '2021_2']]


pivot_table





pivot_table["total_cfr"] = pivot_table.abs().sum(axis = 1)


pivot_table['rank'] = pivot_table['total_cfr'].rank(ascending=False, method='min')


pivot_table = pivot_table.sort_values(by='rank')


















